{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Challenge\n",
    "\n",
    "Now that you have two new regression methods at your fingertips, it's time to give them a spin. In fact, for this challenge, let's put them together! Pick a dataset of your choice with a binary outcome and the potential for at least 15 features. If you're drawing a blank, the crime rates in 2013 dataset has a lot of variables that could be made into a modelable binary outcome.\n",
    "\n",
    "Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:\n",
    "\n",
    "    Vanilla logistic regression\n",
    "    Ridge logistic regression\n",
    "    Lasso logistic regression\n",
    "\n",
    "If you're stuck on how to begin combining your two new modeling skills, here's a hint: the SKlearn LogisticRegression method has a \"penalty\" argument that takes either 'l1' or 'l2' as a value.\n",
    "\n",
    "In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?\n",
    "\n",
    "Record your work and reflections in a notebook to discuss with your mentor.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT EVERYTHING: because why not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT THE DATA: find shape, nulls values, column names, and get the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "\n",
    "print (df.shape)\n",
    "print (df.columns.isnull().sum())\n",
    "print (df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIND OUT THE DISTRIBUTION OF THE DEPENDENT VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCE DUMMY FEATURES FOR SEVERAL INDEPENDENT VARIABLES AND SAVE THEM INTO A NEW DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objlist = df[['Attrition', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']]\n",
    "df2=df.append(pd.get_dummies(objlist, drop_first=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK THE NEW DATAFRAME SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP ORIGINAL VARIABLE 'Attrition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(objlist, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILL IN EMPTY CELLS WITH 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.fillna(0)\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK DISTRIBUTION ON DEPENDENT VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Attrition_Yes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGN DEPENDENT AND INDEPENDENT VARIABLES TO X AND y as well as setup the train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3['Attrition_Yes']\n",
    "X = df3[['Age', 'DailyRate', 'Department_Research & Development', 'Department_Sales',\n",
    "        'DistanceFromHome', 'Education', 'EducationField_Life Sciences',\n",
    "        'EducationField_Marketing', 'EducationField_Medical',\n",
    "       'EducationField_Other', 'EducationField_Technical Degree',\n",
    "       'EmployeeCount',  'EnvironmentSatisfaction',\n",
    "       'Gender_Male', 'HourlyRate', 'JobInvolvement', 'JobLevel',\n",
    "       'JobRole_Human Resources', 'JobRole_Laboratory Technician',\n",
    "       'JobRole_Manager', 'JobRole_Manufacturing Director',\n",
    "       'JobRole_Research Director', 'JobRole_Research Scientist',\n",
    "       'JobRole_Sales Executive', 'JobRole_Sales Representative',\n",
    "       'JobSatisfaction', 'MaritalStatus_Married', 'MaritalStatus_Single',\n",
    "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', \n",
    "       'OverTime_Yes', 'PercentSalaryHike', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT AND UTILIZE AN UNDER-SAMPLING METHOD (RandomUnderSampler) TO HELP CREATE A BALANCED DISTRIBUTION IN THE DEPENDENT VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THE LOGISTIC REGRESSION ON THE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty= 'l1', C=1000)\n",
    "\n",
    "# Fit the model.\n",
    "fit = lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(X)\n",
    "\n",
    "print('\\n Accuracy by Attrition')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARE WITH RUNNING A RIDGE REGRESSION ON THE SAME VARIABLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "ridgeregr.fit(X_resampled, y_resampled)\n",
    "print(ridgeregr.score(X_train, y_train))\n",
    "print(ridgeregr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "par = {'alpha': [0, 1, 2, 3]}\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, par, scoring = 'neg_mean_squared_error', cv = 3)\n",
    "\n",
    "ridge_regressor.fit(X_resampled, y_resampled)\n",
    "\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(ridge_regressor.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARE WITH A LASSO REGRESSION ON THE SAME VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lass = linear_model.Lasso(alpha=.35)\n",
    "lassfit = lass.fit(X_resampled, y_resampled)\n",
    "\n",
    "print(lass.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
